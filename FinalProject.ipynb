{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm\n",
    "Step 1. import URL handling modules - urllib.request,urllib.parse and urllib.error for opening, reading, parsing and displaying exceptions\n",
    "Step 2. import BeautifulSoup. It's a python package to scrape data from given websites\n",
    "Step 3. Provide the url of the CNN website as a string and store it in variable url\n",
    "Step 4. Open the url using urllib.request.urlopen(url) function and store it in variable page\n",
    "Step 5. Create a BeautifulSoup object named soup with the html content of the page\n",
    "Step 6. Inspect the table class name(\"wsod_dataTable wsod_dataTableBigAlt \") containing the details of Most Active stocks only and store it in variable table_MostActive\n",
    "Step 7. Use soup.find_all() method to detect the first table class with name table_MostActive and store it in variable tab\n",
    "Step 8. Iterate through each table row in the table class\n",
    "Step 9. Iterate through each table data in the table row \n",
    "Step 10. With each iteration of the table data, append table data to list l1\n",
    "Step 11. With each iteration of the table row, append list l1 to list data_MostActive\n",
    "Step 12. Slice the data_MostActive list from index 1 to the rest of the elements in the last , to remove the null element present in the first index \n",
    "Step 13. Iterate each element in data_MostActive list\n",
    "Step 14. Retrieve only the ticker symbol from the elements in the zero th index and store it in variable tickersymbols\n",
    "Step 15. Append the tickersymbols to list temp\n",
    "Step 16. Provide the url of the Yahoo Finance website as a string and store it in variable ticketurl\n",
    "Step 17. Iterate each element in temp list\n",
    "Step 18. Request to get the website containing the information of each ticker symbol and store it in variable mystockhandle\n",
    "Step 19. Create a BeautifulSoup object named soup with the html content of mystockhandle\n",
    "Step 20. Inspect the table class name (\"W(100%)\") containing the details two of each ticker symbols and the other class name 'W(100%) M(0) Bdcl(c)' containing one of other ticker symbols\n",
    "Step 21. Use soup.find_all() method to detect the table class with name W(100%) and W(100%) M(0) Bdcl(c) and store it in variables tab and tab2.\n",
    "Step 22. Iterate each table row in the table class\n",
    "Step 23. Iterate each table data in the table row\n",
    "Step 24. With each iteration of the table data, append table data to list l1\n",
    "Step 25. Append only the table data of each ticker symbol to a list proplist\n",
    "Step 26. Create a list with string values Open, Avg Volume, PE Ratio and store it in variable neededprops\n",
    "Step 27. Create a variable counto and initialize it to 0\n",
    "Step 28. Create outer for loop to iterate each element in list proplist \n",
    "Step 29. Create a variable count and initialize it to 0\n",
    "Step 30. Append ticker symbol from temp to list temp1\n",
    "Step 31. Create inner for loop to Iterate each element in the sub list of proplist\n",
    "Step 32. If the element is in neededprops, then append proplist[counto][count+1] to temp1\n",
    "Step 33. Increment count to 1 in order to traverse through each column in the list \n",
    "Step 34. After exiting the inner loop, Append temp1 to list props\n",
    "Step 35. Increment count o to 1 in order to traverse through each row in the list\n",
    "Step 36. Iterate each element in props list\n",
    "Step 37. Replace the (,) delimiters in p[2] with \"\" using replace() method\n",
    "Step 38. import csv module and open the stocks.csv file in write mode as file\n",
    "Step 39. write each data element in props list as indiviual rows in stocks.csv file using writer.writerows(props)\n",
    "Step 40. import sqlite3 and connect to StocksDatabase.sqlite\n",
    "Step 41. Drop the table StocksTable if already exists and create a the table with the Ticker, OpenPrice, Avg Volume, PE Ratio\n",
    "Step 42. Open the stocks.csv file in read mode and store it invariable stockfilehandle\n",
    "Step 43. Write an insert query to accept the values for the columns as a string and store it in variable insertcmd\n",
    "Step 44. Iterate each stock in the stockfilehandle\n",
    "Step 45. rightstrip and split each stock using , delimiter and store it in variable stockdata\n",
    "Step 46. execute the sql insert command by cur.execute() method by inserting the insercmd along with stockdata[0], stockdata[1],stockdata[2],stockdata[3] as the values\n",
    "Step 47. Perform commit function to store the result of the insert operation\n",
    "Step 48. Execute a select operation to retrieve all the rows from StocksTable and display the output\n",
    "Step 49. Exit the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import urllib.request,urllib.parse,urllib.error\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    url = 'https://money.cnn.com/data/hotstocks/'\n",
    "    webpage = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(webpage,'html.parser')\n",
    "    MostActive_tab = \"wsod_dataTable wsod_dataTableBigAlt\"\n",
    "    MostActive_data = []\n",
    "    Symbols_tickers = []\n",
    "    temp = []\n",
    "    tab = soup.find_all('table', attrs={'class':MostActive_tab})[0]\n",
    "    for row in tab.select('tr'):\n",
    "        l1 = []\n",
    "        for data in row.select('td'):\n",
    "        \n",
    "            l1.append(data.text)\n",
    "        MostActive_data.append(l1)\n",
    "    MostActive_data = MostActive_data[1:] #Slice the MostActive_data list from index 1 to to remove the null element present in the first index \n",
    "    #print(MostActive_data)\n",
    "\n",
    "    for i in MostActive_data:\n",
    "        Symbols_tickers = i[0].split(' ')[0]\n",
    "        temp.append(Symbols_tickers)\n",
    "\n",
    "    tUrl = 'https://finance.yahoo.com/quote/{myticker}?p={myticker}&.tsrc=fin-srch-v1'\n",
    "\n",
    "    List_prop = []\n",
    "    companylist = []\n",
    "\n",
    "    for i in temp:\n",
    "        mystockhandle = requests.get(tUrl.format(myticker = i))\n",
    "        soup = BeautifulSoup(mystockhandle.content,'html.parser')\n",
    "        tab = soup.find_all('table',attrs={'class':['W(100%)']})[0]\n",
    "        tab2 = soup.find_all('table',attrs={'class':['W(100%) M(0) Bdcl(c)']})[0]\n",
    "        l1 = []\n",
    "        for row in tab.select('tr'):\n",
    "            for data in row.select('td'):\n",
    "                l1.append(data.text)\n",
    "        for row in tab2.select('tr'):\n",
    "            for data in row.select('td'):\n",
    "                l1.append(data.text)\n",
    "                #print(l1)\n",
    "        List_prop.append(l1)\n",
    "    \n",
    "    Props_needed = ['Open','Avg. Volume', 'PE Ratio (TTM)']\n",
    "    props = []\n",
    "    counto = 0\n",
    "    #print(\"Prop list:\", List_prop)\n",
    "    for out in List_prop:\n",
    "        count = 0\n",
    "        temp1 = []\n",
    "    \n",
    "        temp1.append(temp[counto])\n",
    "        for s in out:\n",
    "            if s in Props_needed:\n",
    "                temp1.append(List_prop[counto][count+1])    \n",
    "            count = count + 1\n",
    "        props.append(temp1)\n",
    "        counto = counto + 1\n",
    "       # print(\"Props:\", props)\n",
    "    for p in props:\n",
    "        p[2] = p[2].replace(\",\",\"\")\n",
    "#         t = p[1]\n",
    "#         p[1] = p[2]\n",
    "#         p[2] = t\n",
    "   # print(\"Props v2:\", props)\n",
    "    import csv\n",
    "    with open('stocks.txt', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(props)\n",
    "except:\n",
    "    print(\"Please provide valid URL, If provided the server might be down.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Actives: \n",
      "('GE', 10.67, 113961563, 30.91)\n",
      "('BAC', 29.2, 60328388, 14.43)\n",
      "('CCL', 23.54, 49481652, 'N/A')\n",
      "('OXY', 16.91, 27689306, 'N/A')\n",
      "('F', 9.26, 65095882, 'N/A')\n",
      "('WFC', 29.5, 42701426, 77.56)\n",
      "('MRO', 6.37, 30120674, 'N/A')\n",
      "('T', 29.37, 38389630, 19.43)\n",
      "('PFE', 39.89, 36275592, 26.23)\n",
      "('NCLH', 26.11, 26501239, 'N/A')\n"
     ]
    }
   ],
   "source": [
    " try:\n",
    "    import sqlite3\n",
    "\n",
    "    con = sqlite3.connect('StocksDatabase.sqlite')\n",
    "    cur = con.cursor()\n",
    "\n",
    "    cur.execute('DROP TABLE IF EXISTS StocksTable')\n",
    "    cur.execute('CREATE TABLE StocksTable(Ticker TEXT, OpenPrice REAL, AvgVolume INTEGER, PERatio REAL)')\n",
    "\n",
    "    stockfilehandle = open('stocks.txt','r')\n",
    "    insertcmd = 'INSERT INTO StocksTable(Ticker,OpenPrice,AvgVolume,PERatio) VALUES (?,?,?,?)'\n",
    "    for stock in stockfilehandle:\n",
    "        stock = stock.rstrip()\n",
    "        stockdata = stock.split(',')\n",
    "        cur.execute(insertcmd,(stockdata[0],stockdata[1],stockdata[2],stockdata[3]))\n",
    "        con.commit()\n",
    "    \n",
    "    cur.close()\n",
    "    stockfilehandle.close()\n",
    "\n",
    "    cur = con.cursor()\n",
    "    print(\"Most Actives: \")\n",
    "    cur.execute('SELECT Ticker,OpenPrice,AvgVolume,PERatio FROM StocksTable')\n",
    "    for row in cur:\n",
    "        print(row)\n",
    "    cur.close()\n",
    "except:\n",
    "    print(\"Something went wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
